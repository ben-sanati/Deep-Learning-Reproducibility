Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 9
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 1.0
	kappa: None
	num_epochs: 10
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 1.0, 1: 0.005, 2: 0.0033333333333333335, 3: 0.0025, 4: 0.002, 5: 0.0016666666666666668, 6: 0.0014285714285714286, 7: 0.00125, 8: 0.0011111111111111111, 9: 0.001}
	Using 4 GPUs

***Beginning Training***
	Epoch[1/10]: Training Loss = 0.78752
	Epoch[2/10]: Training Loss = 0.29744
	Epoch[3/10]: Training Loss = 0.26636
	Epoch[4/10]: Training Loss = 0.25187
	Epoch[5/10]: Training Loss = 0.24187
	Epoch[6/10]: Training Loss = 0.23536
	Epoch[7/10]: Training Loss = 0.22983
	Epoch[8/10]: Training Loss = 0.22340
	Epoch[9/10]: Training Loss = 0.21887
	Epoch[10/10]: Training Loss = 0.21634
***Training Complete***

Final Optimizer Parameters
	alpha : 0.0608254075050354
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 94.170 %
Test Error = 5.830 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
alpha: [1.0, 0.5669194459915161, 0.195597305893898, 0.12975654006004333, 0.15705978870391846, 0.040293000638484955, 0.13589762151241302, 0.09909442812204361, 0.09657327085733414, 0.009550163522362709, 0.0608254075050354]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [0.002269444417953491, 0.787515865278244, 0.2974354508241018, 0.26635656824111936, 0.2518673589626948, 0.24187076751391093, 0.23535646279652914, 0.22983088243802388, 0.22340147653420767, 0.21887181216080984, 0.21633899479707083]
