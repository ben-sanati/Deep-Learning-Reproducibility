Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 8
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 1.0
	kappa: None
	num_epochs: 10
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 1.0, 1: 0.005, 2: 0.0033333333333333335, 3: 0.0025, 4: 0.002, 5: 0.0016666666666666668, 6: 0.0014285714285714286, 7: 0.00125, 8: 0.0011111111111111111}
	Using 4 GPUs

***Beginning Training***
	Epoch[1/10]: Training Loss = 0.83629
	Epoch[2/10]: Training Loss = 0.28947
	Epoch[3/10]: Training Loss = 0.26051
	Epoch[4/10]: Training Loss = 0.25301
	Epoch[5/10]: Training Loss = 0.24560
	Epoch[6/10]: Training Loss = 0.23798
	Epoch[7/10]: Training Loss = 0.23164
	Epoch[8/10]: Training Loss = 0.22594
	Epoch[9/10]: Training Loss = 0.22056
	Epoch[10/10]: Training Loss = 0.21539
***Training Complete***

Final Optimizer Parameters
	alpha : 0.09712523967027664
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 93.970 %
Test Error = 6.030 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
alpha: [1.0, 0.6843706965446472, 0.1961923986673355, 0.15134607255458832, 0.10469599813222885, 0.12461493909358978, 0.09671387076377869, 0.0971406027674675, 0.09714400768280029, 0.09712522476911545, 0.09712523967027664]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [0.002263703735669454, 0.8362891063690185, 0.2894726853529612, 0.26051336561838784, 0.2530108951091766, 0.2456008650223414, 0.2379821541627248, 0.2316365839322408, 0.22594037242730458, 0.22056063532829284, 0.2153914716243744]
