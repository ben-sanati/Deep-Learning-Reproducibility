Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 7
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 1.0
	kappa: None
	num_epochs: 10
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 1.0, 1: 0.005, 2: 0.0033333333333333335, 3: 0.0025, 4: 0.002, 5: 0.0016666666666666668, 6: 0.0014285714285714286, 7: 0.00125}
	Using 4 GPUs

***Beginning Training***
	Epoch[1/10]: Training Loss = 0.79984
	Epoch[2/10]: Training Loss = 0.32038
	Epoch[3/10]: Training Loss = 0.29526
	Epoch[4/10]: Training Loss = 0.28561
	Epoch[5/10]: Training Loss = 0.27394
	Epoch[6/10]: Training Loss = 0.26547
	Epoch[7/10]: Training Loss = 0.25811
	Epoch[8/10]: Training Loss = 0.25358
	Epoch[9/10]: Training Loss = 0.24792
	Epoch[10/10]: Training Loss = 0.24372
***Training Complete***

Final Optimizer Parameters
	alpha : 0.06970889121294022
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 93.290 %
Test Error = 6.710 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
alpha: [1.0, 0.36184951663017273, 0.1939322054386139, 0.046580441296100616, 0.09741435945034027, 0.09853297472000122, 0.07723905891180038, 0.04718368500471115, 0.12773199379444122, 0.06781639158725739, 0.06970889121294022]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [0.0022653924584388734, 0.79984404408137, 0.32037985803286234, 0.29525801908175153, 0.2856097512245178, 0.27394325625101723, 0.26546956985791526, 0.25811353834470113, 0.25357700691223145, 0.24791529672145843, 0.24371932202180227]
