Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 11
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 1.0
	kappa: None
	num_epochs: 20
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 1.0, 1: 0.005, 2: 0.0033333333333333335, 3: 0.0025, 4: 0.002, 5: 0.0016666666666666668, 6: 0.0014285714285714286, 7: 0.00125, 8: 0.0011111111111111111, 9: 0.001, 10: 0.0009090909090909091, 11: 0.0008333333333333334}
	Using 4 GPUs

***Beginning Training***
	Initial Train Loss: 2.2928077096303303
	Epoch[1/20]: Training Loss = 0.76794
	Epoch[2/20]: Training Loss = 0.30379
	Epoch[3/20]: Training Loss = 0.27744
	Epoch[4/20]: Training Loss = 0.26361
	Epoch[5/20]: Training Loss = 0.25290
	Epoch[6/20]: Training Loss = 0.24338
	Epoch[7/20]: Training Loss = 0.23477
	Epoch[8/20]: Training Loss = 0.22693
	Epoch[9/20]: Training Loss = 0.22013
	Epoch[10/20]: Training Loss = 0.21443
	Epoch[11/20]: Training Loss = 0.20922
	Epoch[12/20]: Training Loss = 0.20435
	Epoch[13/20]: Training Loss = 0.19969
	Epoch[14/20]: Training Loss = 0.19528
	Epoch[15/20]: Training Loss = 0.19108
	Epoch[16/20]: Training Loss = 0.18721
	Epoch[17/20]: Training Loss = 0.18332
	Epoch[18/20]: Training Loss = 0.17980
	Epoch[19/20]: Training Loss = 0.17639
	Epoch[20/20]: Training Loss = 0.17298
***Training Complete***

Final Optimizer Parameters
	alpha : 0.10228713601827621
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 95.030 %
Test Error = 4.970 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
alpha: [1.0, 0.4766354560852051, 0.1390254944562912, 0.1324595957994461, 0.12229862809181213, 0.12229850143194199, 0.12229803204536438, 0.12229453772306442, 0.12136973440647125, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621, 0.10228713601827621]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [2.2928077096303303, 0.7679373682975769, 0.3037871677398682, 0.27743757457733154, 0.2636058712005615, 0.252895180384318, 0.24337535127003987, 0.23477168980439503, 0.22692927296161652, 0.22013111826578777, 0.21442779619693755, 0.20921820927460988, 0.20434612446626027, 0.1996919017791748, 0.19528215656280518, 0.1910795088450114, 0.18721297740141551, 0.18332272834777832, 0.17979601380030313, 0.1763901482184728, 0.17297623675664267]
