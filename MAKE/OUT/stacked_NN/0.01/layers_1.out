Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 1
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: None
	num_epochs: 20
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 0.01, 1: 5e-05}
	Using 4 GPUs

***Beginning Training***
	Initial Train Loss: 2.2928077096303303
	Epoch[1/20]: Training Loss = 2.23678
	Epoch[2/20]: Training Loss = 2.06106
	Epoch[3/20]: Training Loss = 1.76809
	Epoch[4/20]: Training Loss = 1.39454
	Epoch[5/20]: Training Loss = 1.06129
	Epoch[6/20]: Training Loss = 0.83520
	Epoch[7/20]: Training Loss = 0.69242
	Epoch[8/20]: Training Loss = 0.59910
	Epoch[9/20]: Training Loss = 0.53499
	Epoch[10/20]: Training Loss = 0.48898
	Epoch[11/20]: Training Loss = 0.45489
	Epoch[12/20]: Training Loss = 0.42905
	Epoch[13/20]: Training Loss = 0.40899
	Epoch[14/20]: Training Loss = 0.39338
	Epoch[15/20]: Training Loss = 0.38049
	Epoch[16/20]: Training Loss = 0.36991
	Epoch[17/20]: Training Loss = 0.36077
	Epoch[18/20]: Training Loss = 0.35280
	Epoch[19/20]: Training Loss = 0.34587
	Epoch[20/20]: Training Loss = 0.33956
***Training Complete***

Final Optimizer Parameters
	alpha : 0.03992651402950287
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 90.760 %
Test Error = 9.240 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
alpha: [0.009999999776482582, 0.013342764228582382, 0.016414744779467583, 0.01941634714603424, 0.02228255569934845, 0.025039000436663628, 0.027734747156500816, 0.03048556298017502, 0.0331692211329937, 0.035629838705062866, 0.037784185260534286, 0.03929489478468895, 0.040288716554641724, 0.03986600041389465, 0.039880696684122086, 0.04011262580752373, 0.04012204334139824, 0.04016866534948349, 0.04001248627901077, 0.04026266187429428, 0.03992651402950287]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [2.2928077096303303, 2.2367755869547525, 2.061061804262797, 1.7680871192932128, 1.394543565305074, 1.0612937111854552, 0.8351955551147461, 0.6924172549883525, 0.5990998812357584, 0.5349896254221598, 0.48897956194877623, 0.4548880858103434, 0.42905026284853615, 0.4089886926015218, 0.39338061911265054, 0.3804926829020182, 0.369913542731603, 0.360768159198761, 0.3528037076155345, 0.34587030448913575, 0.3395567499478658]
