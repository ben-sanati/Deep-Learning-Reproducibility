Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 12
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: None
	num_epochs: 10
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 0.01, 1: 5e-05, 2: 3.3333333333333335e-05, 3: 2.5e-05, 4: 2e-05, 5: 1.6666666666666667e-05, 6: 1.4285714285714285e-05, 7: 1.25e-05, 8: 1.1111111111111112e-05, 9: 1e-05, 10: 9.090909090909091e-06, 11: 8.333333333333334e-06, 12: 7.692307692307692e-06}
	Using 4 GPUs

***Beginning Training***
	Epoch[1/10]: Training Loss = 2.24199
	Epoch[2/10]: Training Loss = 2.06270
	Epoch[3/10]: Training Loss = 1.68113
	Epoch[4/10]: Training Loss = 1.12052
	Epoch[5/10]: Training Loss = 0.72633
	Epoch[6/10]: Training Loss = 0.53168
	Epoch[7/10]: Training Loss = 0.43638
	Epoch[8/10]: Training Loss = 0.38866
	Epoch[9/10]: Training Loss = 0.36245
	Epoch[10/10]: Training Loss = 0.34618
***Training Complete***

Final Optimizer Parameters
	alpha : 0.06710256636142731
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 90.860 %
Test Error = 9.140 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
alpha: [0.009999999776482582, 0.01438121311366558, 0.021515294909477234, 0.0334116667509079, 0.05097123980522156, 0.07613038271665573, 0.10325626283884048, 0.10850980877876282, 0.0973612442612648, 0.08251335471868515, 0.06710256636142731]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [0.002257968219121297, 2.2419922559102377, 2.062698311742147, 1.6811254716237387, 1.1205230954170227, 0.7263323317845662, 0.531681905968984, 0.4363762023925781, 0.38866206310590107, 0.36245254119237263, 0.3461781807104746]
