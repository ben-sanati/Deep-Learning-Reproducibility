Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 2
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: None
	num_epochs: 20
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 0.01, 1: 5e-05, 2: 3.3333333333333335e-05}
	Using 4 GPUs

***Beginning Training***
	Initial Train Loss: 2.2928077096303303
	Epoch[1/20]: Training Loss = 2.23575
	Epoch[2/20]: Training Loss = 2.03970
	Epoch[3/20]: Training Loss = 1.65334
	Epoch[4/20]: Training Loss = 1.14530
	Epoch[5/20]: Training Loss = 0.78291
	Epoch[6/20]: Training Loss = 0.59113
	Epoch[7/20]: Training Loss = 0.48744
	Epoch[8/20]: Training Loss = 0.42737
	Epoch[9/20]: Training Loss = 0.39080
	Epoch[10/20]: Training Loss = 0.36761
	Epoch[11/20]: Training Loss = 0.35154
	Epoch[12/20]: Training Loss = 0.33992
	Epoch[13/20]: Training Loss = 0.33101
	Epoch[14/20]: Training Loss = 0.32433
	Epoch[15/20]: Training Loss = 0.31889
	Epoch[16/20]: Training Loss = 0.31447
	Epoch[17/20]: Training Loss = 0.31046
	Epoch[18/20]: Training Loss = 0.30689
	Epoch[19/20]: Training Loss = 0.30373
	Epoch[20/20]: Training Loss = 0.30066
***Training Complete***

Final Optimizer Parameters
	alpha : 0.03143822401762009
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 91.920 %
Test Error = 8.080 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
alpha: [0.009999999776482582, 0.014358744956552982, 0.020784450694918633, 0.029718991369009018, 0.04053107649087906, 0.053546465933322906, 0.06740116328001022, 0.079339399933815, 0.08686715364456177, 0.08260827511548996, 0.07834110409021378, 0.07023521512746811, 0.0636405199766159, 0.05196888744831085, 0.044902101159095764, 0.04158162698149681, 0.03787996619939804, 0.03692242503166199, 0.0333314873278141, 0.03428340703248978, 0.03143822401762009]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [2.2928077096303303, 2.235753793334961, 2.0397015135447183, 1.6533417373657227, 1.1452994455973307, 0.7829143122355143, 0.5911290334383646, 0.4874381201267242, 0.4273734391848246, 0.39079861749013267, 0.3676077944755554, 0.3515425630728404, 0.3399244077205658, 0.3310122671922048, 0.3243344066778819, 0.3188899036407471, 0.31447059089342755, 0.310455185286204, 0.306891366593043, 0.303730530055364, 0.30066098788579304]
