Args:
	model: stacked_NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {}
	num_hyperoptimizers: 3
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: None
	num_epochs: 20
	batch_size: 1024
	baseline: False
	device: cuda
	Alpha Values: {0: 0.01, 1: 5e-05, 2: 3.3333333333333335e-05, 3: 2.5e-05}
	Using 4 GPUs

***Beginning Training***
	Initial Train Loss: 2.2928077096303303
	Epoch[1/20]: Training Loss = 2.23571
	Epoch[2/20]: Training Loss = 2.03754
	Epoch[3/20]: Training Loss = 1.63148
	Epoch[4/20]: Training Loss = 1.08302
	Epoch[5/20]: Training Loss = 0.70820
	Epoch[6/20]: Training Loss = 0.52260
	Epoch[7/20]: Training Loss = 0.43497
	Epoch[8/20]: Training Loss = 0.39118
	Epoch[9/20]: Training Loss = 0.36527
	Epoch[10/20]: Training Loss = 0.34882
	Epoch[11/20]: Training Loss = 0.33728
	Epoch[12/20]: Training Loss = 0.32924
	Epoch[13/20]: Training Loss = 0.32340
	Epoch[14/20]: Training Loss = 0.31999
	Epoch[15/20]: Training Loss = 0.31761
	Epoch[16/20]: Training Loss = 0.31575
	Epoch[17/20]: Training Loss = 0.31392
	Epoch[18/20]: Training Loss = 0.31211
	Epoch[19/20]: Training Loss = 0.31033
	Epoch[20/20]: Training Loss = 0.30825
***Training Complete***

Final Optimizer Parameters
	alpha : 0.019725453108549118
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 91.660 %
Test Error = 8.340 %
==============================

Plotted Lists:
Epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
alpha: [0.009999999776482582, 0.014431453309953213, 0.021610522642731667, 0.0335492342710495, 0.05133288353681564, 0.07752307504415512, 0.09597126394510269, 0.0961044654250145, 0.09671812504529953, 0.08209455013275146, 0.07295141369104385, 0.05810083821415901, 0.04786260426044464, 0.026073303073644638, 0.018654927611351013, 0.018246542662382126, 0.016000784933567047, 0.018184613436460495, 0.016308365389704704, 0.022333426401019096, 0.019725453108549118]
mu: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Loss: [2.2928077096303303, 2.235713481903076, 2.0375378697077435, 1.6314847959518433, 1.0830212034861246, 0.7081963030179341, 0.5225953953107199, 0.4349685180505117, 0.3911845044930776, 0.3652727227687836, 0.34882042501767474, 0.33728171292940773, 0.3292353323618571, 0.3234034632841746, 0.31999029699961345, 0.31761319162050883, 0.31574537216822307, 0.3139203539212545, 0.3121073735713959, 0.3103317903836568, 0.3082539602915446]
