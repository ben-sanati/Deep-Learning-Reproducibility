Args:
	model: NN
	optimizer: RMSProp
	optimizer_args: {'gamma': 0.99}
	hyperoptimizer: SGD
	hyperoptimizer_args: {}
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: 0.0001
	num_epochs: 30
	batch_size: 256
	device: cuda

***Beginning Training***
	Epoch[1/30]: Training Loss = 0.31344
	Epoch[2/30]: Training Loss = 0.13140
	Epoch[3/30]: Training Loss = 0.10047
	Epoch[4/30]: Training Loss = 0.08344
	Epoch[5/30]: Training Loss = 0.07240
	Epoch[6/30]: Training Loss = 0.06457
	Epoch[7/30]: Training Loss = 0.05879
	Epoch[8/30]: Training Loss = 0.05413
	Epoch[9/30]: Training Loss = 0.04995
	Epoch[10/30]: Training Loss = 0.04670
	Epoch[11/30]: Training Loss = 0.04391
	Epoch[12/30]: Training Loss = 0.04147
	Epoch[13/30]: Training Loss = 0.03935
	Epoch[14/30]: Training Loss = 0.03747
	Epoch[15/30]: Training Loss = 0.03571
	Epoch[16/30]: Training Loss = 0.03429
	Epoch[17/30]: Training Loss = 0.03296
	Epoch[18/30]: Training Loss = 0.03156
	Epoch[19/30]: Training Loss = 0.03046
	Epoch[20/30]: Training Loss = 0.02935
	Epoch[21/30]: Training Loss = 0.02835
	Epoch[22/30]: Training Loss = 0.02753
	Epoch[23/30]: Training Loss = 0.02667
	Epoch[24/30]: Training Loss = 0.02588
	Epoch[25/30]: Training Loss = 0.02519
	Epoch[26/30]: Training Loss = 0.02446
	Epoch[27/30]: Training Loss = 0.02378
	Epoch[28/30]: Training Loss = 0.02319
	Epoch[29/30]: Training Loss = 0.02259
	Epoch[30/30]: Training Loss = 0.02209
***Training Complete***

Final Optimizer Parameters
	alpha : 0.013682768680155277
	gamma : 0.9892114996910095

***Testing Results***
==============================
Test Accuracy = 97.950 %
Test Error = 2.050 %
==============================
