Args:
	model: NN
	optimizer: SGD
	optimizer_args: {}
	hyperoptimizer: RMSProp
	hyperoptimizer_args: {'gamma': 0.99}
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: 0.1
	num_epochs: 30
	batch_size: 256
	device: cuda

***Beginning Training***
	Epoch[1/30]: Training Loss = 0.51889
	Epoch[2/30]: Training Loss = 0.32285
	Epoch[3/30]: Training Loss = 0.28509
	Epoch[4/30]: Training Loss = 0.25826
	Epoch[5/30]: Training Loss = 0.23717
	Epoch[6/30]: Training Loss = 0.21992
	Epoch[7/30]: Training Loss = 0.20680
	Epoch[8/30]: Training Loss = 0.19420
	Epoch[9/30]: Training Loss = 0.18306
	Epoch[10/30]: Training Loss = 0.17260
	Epoch[11/30]: Training Loss = 0.16120
	Epoch[12/30]: Training Loss = 0.15299
	Epoch[13/30]: Training Loss = 0.14567
	Epoch[14/30]: Training Loss = 0.13732
	Epoch[15/30]: Training Loss = 0.13001
	Epoch[16/30]: Training Loss = 0.12491
	Epoch[17/30]: Training Loss = 0.12011
	Epoch[18/30]: Training Loss = 0.11539
	Epoch[19/30]: Training Loss = 0.11198
	Epoch[20/30]: Training Loss = 0.10680
	Epoch[21/30]: Training Loss = 0.10342
	Epoch[22/30]: Training Loss = 0.09929
	Epoch[23/30]: Training Loss = 0.09669
	Epoch[24/30]: Training Loss = 0.09382
	Epoch[25/30]: Training Loss = 0.08976
	Epoch[26/30]: Training Loss = 0.08690
	Epoch[27/30]: Training Loss = 0.08442
	Epoch[28/30]: Training Loss = 0.08078
	Epoch[29/30]: Training Loss = 0.07961
	Epoch[30/30]: Training Loss = 0.07616
***Training Complete***

Final Optimizer Parameters
	alpha : 0.14952848851680756
	mu : 0.0

***Testing Results***
==============================
Test Accuracy = 97.190 %
Test Error = 2.810 %
==============================
