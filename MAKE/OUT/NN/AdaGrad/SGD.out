Args:
	model: NN
	optimizer: AdaGrad
	optimizer_args: {}
	hyperoptimizer: SGD
	hyperoptimizer_args: {}
	loss_fn: CrossEntropyLoss
	dataset: MNIST
	alpha: 0.01
	kappa: 0.01
	num_epochs: 30
	batch_size: 256
	device: cuda

***Beginning Training***
	Epoch[1/30]: Training Loss = 0.61630
	Epoch[2/30]: Training Loss = 0.38453
	Epoch[3/30]: Training Loss = 0.35885
	Epoch[4/30]: Training Loss = 0.34465
	Epoch[5/30]: Training Loss = 0.33664
	Epoch[6/30]: Training Loss = 0.33145
	Epoch[7/30]: Training Loss = 0.32388
	Epoch[8/30]: Training Loss = 0.31589
	Epoch[9/30]: Training Loss = 0.31166
	Epoch[10/30]: Training Loss = 0.30699
	Epoch[11/30]: Training Loss = 0.29885
	Epoch[12/30]: Training Loss = 0.28974
	Epoch[13/30]: Training Loss = 0.28565
	Epoch[14/30]: Training Loss = 0.28420
	Epoch[15/30]: Training Loss = 0.28086
	Epoch[16/30]: Training Loss = 0.27754
	Epoch[17/30]: Training Loss = 0.27349
	Epoch[18/30]: Training Loss = 0.26818
	Epoch[19/30]: Training Loss = 0.26386
	Epoch[20/30]: Training Loss = 0.25982
	Epoch[21/30]: Training Loss = 0.25842
	Epoch[22/30]: Training Loss = 0.25631
	Epoch[23/30]: Training Loss = 0.25324
	Epoch[24/30]: Training Loss = 0.25105
	Epoch[25/30]: Training Loss = 0.24930
	Epoch[26/30]: Training Loss = 0.24688
	Epoch[27/30]: Training Loss = 0.24384
	Epoch[28/30]: Training Loss = 0.24129
	Epoch[29/30]: Training Loss = 0.23905
	Epoch[30/30]: Training Loss = 0.23772
***Training Complete***

Final Optimizer Parameters
	alpha : 0.004365846514701843

***Testing Results***
==============================
Test Accuracy = 93.340 %
Test Error = 6.660 %
==============================
